{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edb6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import json\n",
    "from collections import defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cebb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTIL Funcitons to calculate maetrics\n",
    "\n",
    "def read_results(main_folder=\"results\"):\n",
    "    \"\"\"\n",
    "    Reads the results from the specified main folder and organizes them into a nested dictionary structure.\n",
    "    \n",
    "    Args:\n",
    "        main_folder (str): The path to the main folder containing the results.\n",
    "        \n",
    "    Returns:\n",
    "        list: list with dictionaries with agents, prompts, sections, and their corresponding logs.\n",
    "    \"\"\"\n",
    "    results = defaultdict(lambda: defaultdict(dict))\n",
    "    list_data = []\n",
    "    models = os.listdir(main_folder)\n",
    "    for model in models:\n",
    "        agents = os.listdir(os.path.join(main_folder,model))\n",
    "    for agent in agents:\n",
    "        prompts = os.listdir(os.path.join(main_folder,model,agent))\n",
    "        for prompt in prompts:\n",
    "            sections = os.listdir(os.path.join(main_folder,model,agent,prompt))\n",
    "            for section in sections:\n",
    "                statuses = os.listdir(os.path.join(main_folder,model,agent,prompt,section))\n",
    "                for status in statuses:\n",
    "                    labs = os.listdir(os.path.join(main_folder,model,agent,prompt,section,status))\n",
    "                    for lab in labs:\n",
    "                        file = os.listdir(os.path.join(main_folder,model,agent,prompt,section,status,lab))[0]\n",
    "                        \n",
    "                        with open(os.path.join(main_folder,model,agent,prompt,section,status,lab,file)) as f:\n",
    "                            logs = [json.loads(line) for line in f]\n",
    "\n",
    "                            \n",
    "                            data = {\n",
    "                                'agent':agent,\n",
    "                                'prompt':prompt,\n",
    "                                'section':section,\n",
    "                                'model':model,\n",
    "                                'lab title':lab,\n",
    "                                'status':status,\n",
    "                                'logs':logs\n",
    "                            }\n",
    "\n",
    "                            list_data.append(data)\n",
    "    return list_data\n",
    "\n",
    "\n",
    "def get_metrics(labs):\n",
    "    \"\"\"\n",
    "    Extracts metrics from the provided list of lab results.\n",
    "    \n",
    "    Args:\n",
    "        labs (list): A list of dictionaries containing lab results, where each dictionary includes logs and metadata.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing calculated metrics for each lab\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    for lab in labs:\n",
    "        \n",
    "        #------- DATA EXTRACTION --------\n",
    "        completitions = [log for log in lab['logs'] if log.get('object') == 'chat.completion']\n",
    "        user_messages = [log for log in lab['logs'] if log.get(\"event\") == \"user_message\" ]\n",
    "        assistant_messages = [log for log in lab['logs'] if log.get(\"event\") == \"assistant_message\" ]\n",
    "        model_metadata = [log for log in lab['logs'] if \"model\" in log ]\n",
    "\n",
    "        #model\n",
    "        model = model_metadata[0]['model']\n",
    "\n",
    "        #assistant messages \n",
    "        assistant_contents = [\n",
    "            choice['message']['content']\n",
    "            for co in completitions\n",
    "            for choice in co['choices']\n",
    "        ]\n",
    "\n",
    "        #assistant tools\n",
    "        assistant_tools_calls = [\n",
    "            tool['function']\n",
    "            for co in completitions\n",
    "            for choice in co['choices']\n",
    "            for tool in choice['message']['tool_calls']\n",
    "        ]\n",
    "\n",
    "        #finish reason\n",
    "        finish_reasons = [\n",
    "            choice['finish_reason']\n",
    "            for co in completitions\n",
    "            for choice in co['choices']\n",
    "        ]\n",
    "\n",
    "        #integration of finish reason, assistant_contents, and assistant_tools_calls\n",
    "        assistant_outputs = [{\"message\":a, \"finish_reason\":b,\"tool\":c} for a, b, c in zip(assistant_contents, finish_reasons,assistant_tools_calls)]\n",
    "\n",
    "\n",
    "        #------- METRICS CALCULATION --------\n",
    "        #turns\n",
    "        total_turns = len(user_messages)\n",
    "\n",
    "        #time\n",
    "        active_seconds = [ac['timing']['active_seconds'] for ac in completitions]\n",
    "        idle_seconds = [ac['timing']['idle_seconds'] for ac in completitions]\n",
    "        total_active_seconds = sum(active_seconds)\n",
    "        total_idle_seconds = sum(idle_seconds) \n",
    "        total_seconds = total_active_seconds + total_idle_seconds\n",
    "\n",
    "        #tokens\n",
    "        prompt_tokens = [ac['usage']['prompt_tokens'] for ac in completitions]\n",
    "        completion_tokens = [ac['usage']['completion_tokens'] for ac in completitions]\n",
    "        total_prompt_tokens = sum(prompt_tokens)\n",
    "        total_completion_tokens = sum(completion_tokens)\n",
    "        total_tokens = total_prompt_tokens + total_completion_tokens\n",
    "\n",
    "        #costs\n",
    "        interaction_costs = [ac['cost']['interaction_cost'] for ac in completitions]\n",
    "        total_interaction_costs = sum(interaction_costs)\n",
    "\n",
    "        #assistant outputs\n",
    "        total_assistant_messages = len([x for x in assistant_contents if x is not None])\n",
    "\n",
    "        #assistant tools\n",
    "        total_assistant_tools = len([x for x in assistant_tools_calls])\n",
    "\n",
    "        metrics = {\n",
    "            \"agent\": lab['agent'],\n",
    "            \"prompt\": lab['prompt'],\n",
    "            \"section\": lab['section'],\n",
    "            \"model\": lab['model'],\n",
    "            \"lab_title\": lab['lab title'],\n",
    "            \"status\": lab['status'],\n",
    "            \"turns\": total_turns,\n",
    "            \"active_seconds\": total_active_seconds,\n",
    "            \"idle_seconds\": total_idle_seconds,\n",
    "            \"total_seconds\": total_seconds,\n",
    "            \"prompt_tokens\": total_prompt_tokens,\n",
    "            \"completion_tokens\": total_completion_tokens,\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"interaction_costs\": total_interaction_costs,\n",
    "            \"total_assistant_messages\": total_assistant_messages,\n",
    "            \"total_assistant_tools\": total_assistant_tools,\n",
    "            \"assistant_outputs\": json.dumps(assistant_outputs) \n",
    "        }\n",
    "        results.append(metrics)\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "131d62a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = read_results()    \n",
    "metrics = get_metrics(results)\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "\n",
    "#calcualte the mean of the metrics\n",
    "mean_metrics = (df_metrics.drop(columns=['status',\n",
    "                                         'lab_title',\n",
    "                                         'assistant_outputs'\n",
    "                            ]).groupby(['agent', \n",
    "                                        'prompt', \n",
    "                                        'section', \n",
    "                                        'model'])\n",
    "                            .mean()\n",
    "                            .reset_index())\n",
    "\n",
    "\n",
    "#calculate the sum of status metric\n",
    "df_metrics = pd.get_dummies(df_metrics, columns=['status'],prefix='',prefix_sep='')\n",
    "df_metrics[['interrupted','not-solved','solved']] = df_metrics[['interrupted','not-solved','solved']].astype(int)\n",
    "status_metrics = (df_metrics.drop(columns=['lab_title',\n",
    "                                          'assistant_outputs'])\n",
    "                            .groupby(['agent', \n",
    "                                      'prompt', \n",
    "                                      'section', \n",
    "                                      'model'])\n",
    "                            [['interrupted','not-solved','solved']]\n",
    "                            .sum()\n",
    "                            .reset_index())\n",
    "\n",
    "\n",
    "\n",
    "df_calculated_metrics = pd.merge(mean_metrics, status_metrics, on=['agent', 'prompt', 'section', 'model'])\n",
    "df_calculated_metrics = df_calculated_metrics.rename(columns={\n",
    "    'turns': 'avg_turns',\n",
    "    'active_seconds': 'avg_active_seconds',\n",
    "    'idle_seconds': 'avg_idle_seconds',\n",
    "    'total_seconds': 'avg_total_seconds',\n",
    "    'prompt_tokens': 'avg_prompt_tokens',\n",
    "    'completion_tokens': 'avg_completion_tokens',\n",
    "    'total_tokens': 'avg_total_tokens',\n",
    "    'interaction_costs': 'avg_interaction_costs', \n",
    "    'total_assistant_messages': 'avg_total_assistant_messages',\n",
    "    'total_assistant_tools': 'avg_total_assistant_tools',   \n",
    "    'interrupted': 'total_interrupted',\n",
    "    'not-solved': 'total_not_solved',\n",
    "    'solved': 'total_solved'\n",
    "})\n",
    "\n",
    "#save the dataframe to a excel file\n",
    "df_metrics.to_excel('metrics_experiment/evaluation_metrics.xlsx', index=False)\n",
    "df_calculated_metrics.to_excel('metrics_experiment/calculated_evaluation_metrics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "546ac20b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "section",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "avg_turns",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_active_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_idle_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_total_seconds",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_prompt_tokens",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_completion_tokens",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_total_tokens",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_interaction_costs",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_total_assistant_messages",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "avg_total_assistant_tools",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_interrupted",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_not_solved",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_solved",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "1e9bb03d-9756-44fa-9b1c-b8d57ba24503",
       "rows": [
        [
         "0",
         "webbounty",
         "chain-of-thought",
         "cross-site-request-forgery-csrf",
         "openai-gpt-4o",
         "1.4",
         "99.6",
         "272.0",
         "371.6",
         "12448.0",
         "929.6",
         "13377.6",
         "0.0",
         "1.2",
         "0.4",
         "0",
         "5",
         "0"
        ],
        [
         "1",
         "webbounty",
         "chain-of-thought",
         "cross-site-scripting",
         "openai-gpt-4o",
         "1.0",
         "36.8",
         "27.0",
         "63.8",
         "6904.8",
         "1145.6",
         "8050.4",
         "0.0",
         "1.0",
         "0.0",
         "0",
         "5",
         "0"
        ],
        [
         "2",
         "webbounty",
         "chain-of-thought",
         "sql-injection",
         "openai-gpt-4o",
         "1.2",
         "73.6",
         "153.6",
         "227.2",
         "6969.6",
         "1027.8",
         "7997.4",
         "0.0",
         "1.2",
         "0.2",
         "0",
         "5",
         "0"
        ],
        [
         "3",
         "webbounty",
         "few-shot",
         "cross-site-request-forgery-csrf",
         "openai-gpt-4o",
         "1.0",
         "59.8",
         "139.0",
         "198.8",
         "10411.6",
         "769.0",
         "11180.6",
         "0.0",
         "1.0",
         "0.0",
         "0",
         "5",
         "0"
        ],
        [
         "4",
         "webbounty",
         "few-shot",
         "cross-site-scripting",
         "openai-gpt-4o",
         "2.2",
         "206.0",
         "235.4",
         "441.4",
         "29825.2",
         "857.4",
         "30682.6",
         "0.0",
         "1.4",
         "1.2",
         "0",
         "4",
         "1"
        ],
        [
         "5",
         "webbounty",
         "few-shot",
         "sql-injection",
         "openai-gpt-4o",
         "2.4",
         "237.8",
         "292.4",
         "530.2",
         "32166.0",
         "715.6",
         "32881.6",
         "0.0",
         "1.4",
         "1.4",
         "0",
         "4",
         "1"
        ],
        [
         "6",
         "webbounty",
         "zero-shot",
         "cross-site-request-forgery-csrf",
         "openai-gpt-4o",
         "1.0",
         "41.2",
         "61.0",
         "102.2",
         "4088.6",
         "475.2",
         "4563.8",
         "0.0",
         "1.0",
         "0.0",
         "0",
         "5",
         "0"
        ],
        [
         "7",
         "webbounty",
         "zero-shot",
         "cross-site-scripting",
         "openai-gpt-4o",
         "2.8",
         "309.2",
         "89.2",
         "398.4",
         "22420.6",
         "952.6",
         "23373.2",
         "0.0",
         "2.0",
         "2.0",
         "0",
         "4",
         "1"
        ],
        [
         "8",
         "webbounty",
         "zero-shot",
         "sql-injection",
         "openai-gpt-4o",
         "5.0",
         "2088.4",
         "340.0",
         "2428.4",
         "43830.8",
         "1190.6",
         "45021.4",
         "0.0",
         "2.4",
         "4.4",
         "2",
         "2",
         "1"
        ]
       ],
       "shape": {
        "columns": 17,
        "rows": 9
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>prompt</th>\n",
       "      <th>section</th>\n",
       "      <th>model</th>\n",
       "      <th>avg_turns</th>\n",
       "      <th>avg_active_seconds</th>\n",
       "      <th>avg_idle_seconds</th>\n",
       "      <th>avg_total_seconds</th>\n",
       "      <th>avg_prompt_tokens</th>\n",
       "      <th>avg_completion_tokens</th>\n",
       "      <th>avg_total_tokens</th>\n",
       "      <th>avg_interaction_costs</th>\n",
       "      <th>avg_total_assistant_messages</th>\n",
       "      <th>avg_total_assistant_tools</th>\n",
       "      <th>total_interrupted</th>\n",
       "      <th>total_not_solved</th>\n",
       "      <th>total_solved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>cross-site-request-forgery-csrf</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>1.4</td>\n",
       "      <td>99.6</td>\n",
       "      <td>272.0</td>\n",
       "      <td>371.6</td>\n",
       "      <td>12448.0</td>\n",
       "      <td>929.6</td>\n",
       "      <td>13377.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>cross-site-scripting</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>63.8</td>\n",
       "      <td>6904.8</td>\n",
       "      <td>1145.6</td>\n",
       "      <td>8050.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>chain-of-thought</td>\n",
       "      <td>sql-injection</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>1.2</td>\n",
       "      <td>73.6</td>\n",
       "      <td>153.6</td>\n",
       "      <td>227.2</td>\n",
       "      <td>6969.6</td>\n",
       "      <td>1027.8</td>\n",
       "      <td>7997.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>cross-site-request-forgery-csrf</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>139.0</td>\n",
       "      <td>198.8</td>\n",
       "      <td>10411.6</td>\n",
       "      <td>769.0</td>\n",
       "      <td>11180.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>cross-site-scripting</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>2.2</td>\n",
       "      <td>206.0</td>\n",
       "      <td>235.4</td>\n",
       "      <td>441.4</td>\n",
       "      <td>29825.2</td>\n",
       "      <td>857.4</td>\n",
       "      <td>30682.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>few-shot</td>\n",
       "      <td>sql-injection</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>2.4</td>\n",
       "      <td>237.8</td>\n",
       "      <td>292.4</td>\n",
       "      <td>530.2</td>\n",
       "      <td>32166.0</td>\n",
       "      <td>715.6</td>\n",
       "      <td>32881.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>cross-site-request-forgery-csrf</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>102.2</td>\n",
       "      <td>4088.6</td>\n",
       "      <td>475.2</td>\n",
       "      <td>4563.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>cross-site-scripting</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>2.8</td>\n",
       "      <td>309.2</td>\n",
       "      <td>89.2</td>\n",
       "      <td>398.4</td>\n",
       "      <td>22420.6</td>\n",
       "      <td>952.6</td>\n",
       "      <td>23373.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>webbounty</td>\n",
       "      <td>zero-shot</td>\n",
       "      <td>sql-injection</td>\n",
       "      <td>openai-gpt-4o</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2088.4</td>\n",
       "      <td>340.0</td>\n",
       "      <td>2428.4</td>\n",
       "      <td>43830.8</td>\n",
       "      <td>1190.6</td>\n",
       "      <td>45021.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       agent            prompt                          section  \\\n",
       "0  webbounty  chain-of-thought  cross-site-request-forgery-csrf   \n",
       "1  webbounty  chain-of-thought             cross-site-scripting   \n",
       "2  webbounty  chain-of-thought                    sql-injection   \n",
       "3  webbounty          few-shot  cross-site-request-forgery-csrf   \n",
       "4  webbounty          few-shot             cross-site-scripting   \n",
       "5  webbounty          few-shot                    sql-injection   \n",
       "6  webbounty         zero-shot  cross-site-request-forgery-csrf   \n",
       "7  webbounty         zero-shot             cross-site-scripting   \n",
       "8  webbounty         zero-shot                    sql-injection   \n",
       "\n",
       "           model  avg_turns  avg_active_seconds  avg_idle_seconds  \\\n",
       "0  openai-gpt-4o        1.4                99.6             272.0   \n",
       "1  openai-gpt-4o        1.0                36.8              27.0   \n",
       "2  openai-gpt-4o        1.2                73.6             153.6   \n",
       "3  openai-gpt-4o        1.0                59.8             139.0   \n",
       "4  openai-gpt-4o        2.2               206.0             235.4   \n",
       "5  openai-gpt-4o        2.4               237.8             292.4   \n",
       "6  openai-gpt-4o        1.0                41.2              61.0   \n",
       "7  openai-gpt-4o        2.8               309.2              89.2   \n",
       "8  openai-gpt-4o        5.0              2088.4             340.0   \n",
       "\n",
       "   avg_total_seconds  avg_prompt_tokens  avg_completion_tokens  \\\n",
       "0              371.6            12448.0                  929.6   \n",
       "1               63.8             6904.8                 1145.6   \n",
       "2              227.2             6969.6                 1027.8   \n",
       "3              198.8            10411.6                  769.0   \n",
       "4              441.4            29825.2                  857.4   \n",
       "5              530.2            32166.0                  715.6   \n",
       "6              102.2             4088.6                  475.2   \n",
       "7              398.4            22420.6                  952.6   \n",
       "8             2428.4            43830.8                 1190.6   \n",
       "\n",
       "   avg_total_tokens  avg_interaction_costs  avg_total_assistant_messages  \\\n",
       "0           13377.6                    0.0                           1.2   \n",
       "1            8050.4                    0.0                           1.0   \n",
       "2            7997.4                    0.0                           1.2   \n",
       "3           11180.6                    0.0                           1.0   \n",
       "4           30682.6                    0.0                           1.4   \n",
       "5           32881.6                    0.0                           1.4   \n",
       "6            4563.8                    0.0                           1.0   \n",
       "7           23373.2                    0.0                           2.0   \n",
       "8           45021.4                    0.0                           2.4   \n",
       "\n",
       "   avg_total_assistant_tools  total_interrupted  total_not_solved  \\\n",
       "0                        0.4                  0                 5   \n",
       "1                        0.0                  0                 5   \n",
       "2                        0.2                  0                 5   \n",
       "3                        0.0                  0                 5   \n",
       "4                        1.2                  0                 4   \n",
       "5                        1.4                  0                 4   \n",
       "6                        0.0                  0                 5   \n",
       "7                        2.0                  0                 4   \n",
       "8                        4.4                  2                 2   \n",
       "\n",
       "   total_solved  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  \n",
       "5             1  \n",
       "6             0  \n",
       "7             1  \n",
       "8             1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calculated_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7679ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
